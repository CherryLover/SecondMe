# SecondMe - 记忆提炼系统设计

## 概述

本文档描述记忆系统的优化方案：从"存储所有对话"改为"智能提炼有价值的记忆"。

### 问题背景

当前记忆系统的问题：
1. **记忆冗余**：每条消息都存储，包括无意义的闲聊（"你好"、"谢谢"）
2. **信息碎片**：对话被割裂存储，缺乏完整语义
3. **质量不高**：没有筛选和提炼，记忆价值参差不齐

### 优化目标

- 只记忆有长期价值的信息
- 自动提炼、去重、更新记忆
- 后台静默执行，用户无感知

---

## 核心机制

### 触发时机

```
用户发消息 → 更新话题 last_active_at → 继续对话...
                        ↓
              [后台定时任务每 30 秒检查]
                        ↓
              话题静默超过 N 分钟？（可配置）
                        ↓ 是
              有未处理的新消息？
                        ↓ 是
              调用 AI 提炼记忆
                        ↓
              存储/更新/跳过
                        ↓
              标记处理完成
```

### 提炼范围

每次只处理**新增的消息**（自上次提炼后的消息），但会带上最近的上下文帮助理解。

```
[上下文消息 - 仅供理解，不从中提取]
用户：缓存方案用 Redis 还是 Memcached？
AI：取决于你的需求...

[新消息 - 从这里提取记忆]  ← 只处理这部分
用户：我决定用 Redis 了
AI：好的选择...
```

### 去重与更新

提炼时会检索已有的相关记忆，由 AI 判断：
- **新增**：全新的信息
- **更新**：对已有记忆的补充或修正
- **跳过**：重复或无价值的信息

---

## 记忆类型

| type 值 | 说明 | 示例 |
|---------|------|------|
| `personal` | 个人信息 | "用户叫张三，是后端工程师" |
| `preference` | 偏好习惯 | "用户喜欢简洁的代码风格" |
| `fact` | 重要事实 | "用户的项目使用 FastAPI + Vue" |
| `plan` | 计划决定 | "用户计划下周重构登录模块" |
| `manual` | 手动添加 | 用户主动添加的记忆 |

---

## 数据结构变更

### topics 表新增字段

```sql
ALTER TABLE topics ADD COLUMN last_active_at TEXT;           -- 最后活跃时间
ALTER TABLE topics ADD COLUMN memory_processed_at TEXT;      -- 记忆处理时间
ALTER TABLE topics ADD COLUMN last_processed_message_id TEXT; -- 上次处理到的消息ID
```

### memories 表新增字段

```sql
ALTER TABLE memories ADD COLUMN memory_type TEXT DEFAULT 'chat';  -- 记忆类型
```

| 字段 | 类型 | 说明 |
|------|------|------|
| `memory_type` | TEXT | personal/preference/fact/plan/manual |

### settings 表新增配置

| key | 默认值 | 说明 |
|-----|--------|------|
| `memory_silent_minutes` | 2 | 静默多久后触发提炼（分钟） |
| `memory_extraction_enabled` | true | 是否启用自动提炼 |
| `memory_context_messages` | 6 | 提炼时携带的上下文消息数 |

---

## 后台任务设计

### 任务调度

```python
import asyncio
from datetime import datetime, timedelta

class MemoryExtractionTask:
    """记忆提炼后台任务"""

    def __init__(self):
        self.check_interval = 30  # 检查间隔（秒）
        self.running = False

    async def start(self):
        """启动后台任务"""
        self.running = True
        while self.running:
            await self.check_and_extract()
            await asyncio.sleep(self.check_interval)

    async def check_and_extract(self):
        """检查并提炼记忆"""
        settings = get_settings()

        if not settings.get("memory_extraction_enabled", True):
            return

        silent_minutes = int(settings.get("memory_silent_minutes", 2))
        threshold = datetime.now() - timedelta(minutes=silent_minutes)

        # 查找需要处理的话题
        topics = find_topics_need_processing(threshold)

        for topic in topics:
            await self.extract_topic_memories(topic)

    async def extract_topic_memories(self, topic: dict):
        """提炼单个话题的记忆"""
        # 1. 获取新消息
        new_messages = get_unprocessed_messages(topic)
        if not new_messages:
            return

        # 2. 获取上下文消息
        context_messages = get_context_messages(topic, limit=6)

        # 3. 搜索相关的已有记忆
        query_text = " ".join([m["content"] for m in new_messages])
        existing_memories = search_related_memories(query_text, top_k=10)

        # 4. 调用 AI 提炼
        result = await call_extraction_ai(
            context_messages=context_messages,
            new_messages=new_messages,
            existing_memories=existing_memories
        )

        # 5. 处理结果
        for mem in result.get("add", []):
            create_extracted_memory(mem, topic["id"])

        for mem in result.get("update", []):
            update_memory(mem["id"], mem["content"])

        # 6. 标记处理完成
        mark_topic_processed(topic["id"], new_messages[-1]["id"])
```

### 查找待处理话题

```python
def find_topics_need_processing(threshold: datetime) -> list[dict]:
    """
    查找需要提炼记忆的话题
    条件：
    1. last_active_at < threshold（静默超过阈值）
    2. last_active_at > memory_processed_at 或 memory_processed_at 为空（有新消息）
    """
    return db.execute("""
        SELECT * FROM topics
        WHERE last_active_at IS NOT NULL
          AND last_active_at < ?
          AND (memory_processed_at IS NULL OR last_active_at > memory_processed_at)
    """, (threshold.isoformat(),))
```

### 获取未处理消息

```python
def get_unprocessed_messages(topic: dict) -> list[dict]:
    """获取话题中未处理的消息"""
    last_processed_id = topic.get("last_processed_message_id")

    if last_processed_id:
        # 获取该消息之后的所有消息
        return db.execute("""
            SELECT * FROM messages
            WHERE topic_id = ?
              AND created_at > (SELECT created_at FROM messages WHERE id = ?)
            ORDER BY created_at ASC
        """, (topic["id"], last_processed_id))
    else:
        # 获取话题所有消息
        return db.execute("""
            SELECT * FROM messages
            WHERE topic_id = ?
            ORDER BY created_at ASC
        """, (topic["id"],))
```

---

## AI 提炼 Prompt

```python
EXTRACTION_PROMPT = """你是记忆管理助手。分析对话内容，提取值得长期记住的信息。

## 已有相关记忆
{existing_memories}

## 最近对话（上下文，仅供理解）
{context_messages}

## 新对话内容（从这里提取）
{new_messages}

## 提取规则
1. 只提取有长期价值的信息
2. 忽略：闲聊、问候、感谢、临时性讨论
3. 用简洁的陈述句，每条记忆独立完整
4. 与已有记忆对比：
   - 完全重复 → 跳过
   - 信息更新/补充 → 标记更新（提供原记忆ID）
   - 全新信息 → 添加

## 记忆类型
- personal: 个人信息（姓名、职业、家庭等）
- preference: 偏好习惯（喜好、风格、习惯）
- fact: 重要事实（项目信息、技术栈等）
- plan: 计划决定（待办、目标、承诺）

## 输出格式（严格 JSON）
{
  "add": [
    {"type": "personal", "content": "用户叫张三，是后端开发工程师"},
    {"type": "fact", "content": "用户正在开发一个 AI 对话助手项目，使用 FastAPI"}
  ],
  "update": [
    {"id": "原记忆ID", "content": "更新后的完整内容"}
  ],
  "reason": "简要说明提取/跳过的原因"
}

如果没有值得记忆的内容：
{
  "add": [],
  "update": [],
  "reason": "对话内容为日常闲聊，无需记忆"
}
"""
```

### Prompt 填充示例

```
## 已有相关记忆
[ID:mem-001] 用户是程序员
[ID:mem-002] 用户在做一个 AI 项目

## 最近对话（上下文，仅供理解）
用户：这个项目的技术栈怎么选？
AI：可以考虑 FastAPI 或 Flask...

## 新对话内容（从这里提取）
用户：我决定用 FastAPI 了，后端就用 Python
AI：好的，FastAPI 是个不错的选择
用户：对了，我叫李明，以后你记得叫我名字
AI：好的李明，我记住了
```

### 期望输出

```json
{
  "add": [
    {"type": "personal", "content": "用户叫李明"}
  ],
  "update": [
    {"id": "mem-002", "content": "用户正在开发一个 AI 项目，使用 FastAPI + Python"}
  ],
  "reason": "提取了用户姓名，更新了项目技术栈信息"
}
```

---

## API 变更

### 现有 API 调整

#### POST /api/topics/{id}/messages
#### POST /api/topics/{id}/messages/stream

变更：
- 不再每条消息都存储记忆
- 更新 `topics.last_active_at`

```python
# 移除
_store_message_memory(user_message, settings)
_store_message_memory(assistant_message, settings)

# 新增
database.update_topic_active_time(topic_id)
```

### 新增 API

#### GET /api/settings

新增返回字段：
```json
{
  "memory_silent_minutes": 2,
  "memory_extraction_enabled": true,
  "memory_context_messages": 6
}
```

#### PUT /api/settings

新增可配置字段：
```json
{
  "memory_silent_minutes": 2,
  "memory_extraction_enabled": true,
  "memory_context_messages": 6
}
```

#### POST /api/topics/{id}/extract-memories（可选）

手动触发记忆提炼，用于调试或用户主动触发。

```json
// Response
{
  "added": 2,
  "updated": 1,
  "skipped": true,
  "reason": "提取了2条新记忆，更新了1条"
}
```

---

## 需要修改的文件

### 数据库层

| 文件 | 修改内容 |
|------|----------|
| `server/database.py` | 新增字段、新增函数 |

新增函数：
- `update_topic_active_time(topic_id)` - 更新话题活跃时间
- `find_topics_need_processing(threshold)` - 查找待处理话题
- `get_unprocessed_messages(topic)` - 获取未处理消息
- `get_context_messages(topic_id, limit)` - 获取上下文消息
- `mark_topic_processed(topic_id, message_id)` - 标记处理完成
- `create_extracted_memory(memory, topic_id)` - 创建提炼的记忆

### AI 层

| 文件 | 修改内容 |
|------|----------|
| `server/ai_client.py` | 新增提炼函数 |

新增函数：
- `extract_memories(provider_id, model, prompt)` - 调用 AI 提炼记忆

### 记忆层

| 文件 | 修改内容 |
|------|----------|
| `server/memory.py` | 新增搜索函数 |

新增函数：
- `search_related_memories(query, top_k)` - 搜索相关记忆（用于去重）

### 主程序

| 文件 | 修改内容 |
|------|----------|
| `server/main.py` | 移除旧逻辑、启动后台任务 |

修改：
- `send_message()` - 移除 `_store_message_memory`，新增更新活跃时间
- `send_message_stream()` - 同上
- 新增后台任务启动逻辑

### 新增文件

| 文件 | 说明 |
|------|------|
| `server/extraction.py` | 记忆提炼模块 |

包含：
- `MemoryExtractionTask` - 后台任务类
- `extract_topic_memories()` - 提炼逻辑
- `EXTRACTION_PROMPT` - 提炼 prompt
- `parse_extraction_result()` - 解析 AI 返回

### 配置层

| 文件 | 修改内容 |
|------|----------|
| `server/config.py` | 新增默认配置 |
| `server/models.py` | 新增 Pydantic 模型 |

---

## 实施步骤

### 第一阶段：数据库准备
1. 修改 `database.py`，新增字段和函数
2. 编写数据库迁移（ALTER TABLE）

### 第二阶段：核心逻辑
1. 创建 `extraction.py` 模块
2. 实现提炼 prompt 和解析逻辑
3. 实现后台任务

### 第三阶段：集成
1. 修改 `main.py`，移除旧的记忆存储逻辑
2. 集成后台任务启动
3. 更新 settings API

### 第四阶段：测试
1. 测试静默检测逻辑
2. 测试提炼质量
3. 测试去重和更新

---

## 回滚方案

如果新方案出现问题，可以：
1. 设置 `memory_extraction_enabled = false` 禁用提炼
2. 在 `main.py` 中恢复 `_store_message_memory` 调用
3. 新旧记忆可以共存，不影响检索

---

## 注意事项

1. **AI 调用成本**：每次提炼会消耗 token，但比每条消息都向量化更经济
2. **提炼模型选择**：建议使用与对话相同的模型，保证理解能力
3. **错误处理**：提炼失败不应影响正常对话，需要完善的错误处理
4. **首次运行**：已有的旧消息不会自动提炼，可以手动触发或忽略
