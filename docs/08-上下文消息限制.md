# 上下文消息数量限制

## 背景

当前发送消息给 AI 时，会将话题下的**所有历史消息**都发送给 AI 作为上下文。随着对话变长，这会导致：

1. **可能超出模型上下文限制** - 不同模型有不同的上下文窗口（4K、8K、128K 等），超出会报错
2. **Token 消耗增加** - 每次请求都发送全部历史
3. **响应变慢** - 处理更多 token 需要更多时间

## 方案

添加一个环境变量配置项 `MAX_CONTEXT_MESSAGES`，限制发送给 AI 的历史消息数量。

- 默认值：100 条
- 只取最近 N 条消息发送给 AI
- 不影响前端显示（前端仍显示全部历史）
- 不影响记忆系统（记忆仍基于全部对话）

## 实现

### 1. 配置项

在 `server/config.py` 中添加：

```python
MAX_CONTEXT_MESSAGES = int(os.getenv("MAX_CONTEXT_MESSAGES", "100"))
```

### 2. 消息截取

在 `server/main.py` 的 `send_message()` 和 `send_message_stream()` 中，获取历史消息后截取最近 N 条：

```python
# 获取历史消息
messages = database.get_messages(topic_id)

# 只取最近 N 条作为上下文
if len(messages) > config.MAX_CONTEXT_MESSAGES:
    messages = messages[-config.MAX_CONTEXT_MESSAGES:]

chat_messages = [{"role": m["role"], "content": m["content"]} for m in messages]
```

## 涉及文件

| 文件 | 变更类型 | 说明 |
|------|----------|------|
| `server/config.py` | 修改 | 新增 `MAX_CONTEXT_MESSAGES` 配置项 |
| `server/main.py` | 修改 | 发送消息时截取最近 N 条 |

## 使用方式

在 `.env` 文件中配置（可选）：

```env
MAX_CONTEXT_MESSAGES=100
```

如果不配置，默认使用 100 条。
