# SecondMe - 记忆系统设计

## 概述

记忆系统是 SecondMe 的核心功能，使用 ChromaDB 作为向量数据库，实现跨话题的长期记忆检索。支持自动记忆（对话生成）和手动记忆（用户主动添加），并记录每条记忆的使用情况。

## 技术选型

**ChromaDB**
- 本地向量数据库，无需额外服务
- 底层使用 SQLite 存储，与项目技术栈一致
- 支持自定义 embedding 函数
- 数据持久化到本地文件

**Embedding 来源**
- 支持多服务商：使用用户配置的 AI 服务商进行向量化
- 可选择不同的 embedding 模型
- 对话和向量化可以使用不同的服务商/模型

## 记忆类型

| 类型 | source 值 | 说明 |
|------|-----------|------|
| 对话记忆 | `chat` | 对话过程中自动生成的记忆 |
| 手动记忆 | `manual` | 用户主动添加的记忆 |

## 数据结构

### SQLite 存储（元数据）

```python
# memories 表
{
    "id": "memory-uuid",
    "content": "记忆内容文本",
    "source": "chat/manual",
    "source_topic_id": "topic-uuid",      # chat 类型才有
    "source_message_id": "message-uuid",  # chat 类型才有
    "use_count": 5,
    "created_at": "timestamp",
    "last_used_at": "timestamp"
}

# memory_usage 表（使用记录）
{
    "id": "usage-uuid",
    "memory_id": "memory-uuid",
    "topic_id": "topic-uuid",
    "message_id": "message-uuid",
    "used_at": "timestamp"
}
```

### ChromaDB 存储（向量）

```python
{
    "id": "memory-uuid",           # 与 SQLite 中的 memory ID 对应
    "document": "记忆内容",         # 原始文本
    "embedding": [...],            # 向量（由配置的 embedding 服务生成）
    "metadata": {
        "source": "chat/manual"
    }
}
```

## 核心流程

### 1. 对话记忆存储流程

```
用户发送消息
    │
    ▼
┌─────────────────────────────────────┐
│ 1. 存储用户消息到 SQLite (messages)  │
│ 2. 创建记忆记录到 SQLite (memories)  │
│ 3. 调用 embedding API 向量化         │
│ 4. 存储向量到 ChromaDB               │
└─────────────────────────────────────┘
    │
    ▼
    ... AI 生成回复 ...
    │
    ▼
┌─────────────────────────────────────┐
│ 1. 存储 AI 回复到 SQLite (messages)  │
│ 2. 创建记忆记录到 SQLite (memories)  │
│ 3. 调用 embedding API 向量化         │
│ 4. 存储向量到 ChromaDB               │
└─────────────────────────────────────┘
```

### 2. 手动记忆存储流程

```
用户添加记忆
    │
    ▼
┌─────────────────────────────────────┐
│ 1. 创建记忆记录到 SQLite (memories)  │
│    - source = "manual"              │
│    - source_topic_id = null         │
│    - source_message_id = null       │
│ 2. 调用 embedding API 向量化         │
│ 3. 存储向量到 ChromaDB               │
└─────────────────────────────────────┘
```

### 3. 记忆检索流程

```
用户新消息
    │
    ▼
┌─────────────────────────────────────┐
│ 1. 调用 embedding API 向量化问题     │
│ 2. 在 ChromaDB 中搜索相似内容        │
│    - 搜索范围：所有记忆              │
│    - 可选：排除当前话题的记忆        │
│    - 返回：Top-K 条最相关记忆        │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 3. 记录使用情况                      │
│    - 插入 memory_usage 记录          │
│    - 更新 use_count 和 last_used_at  │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 4. 将记忆注入 System Prompt          │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 5. 调用 AI API 生成回复              │
│    - 返回使用的记忆 ID 列表          │
└─────────────────────────────────────┘
```

### 4. Prompt 构建

```python
system_prompt = """你是一个有记忆能力的 AI 助手。

以下是与当前问题相关的历史记忆：
---
{相关记忆内容，每条记忆带编号}
---

请结合这些记忆和当前对话来回答用户的问题。如果记忆中有相关信息，可以主动提及。
"""
```

## 配置参数

通过 settings 表配置：

| 配置项 | 说明 | 默认值 |
|--------|------|--------|
| embedding_provider_id | 向量化使用的服务商 | - |
| embedding_model | 向量化使用的模型 | text-embedding-3-small |
| memory_top_k | 检索返回的记忆条数 | 5 |

## 代码示例

### 初始化 ChromaDB

```python
import chromadb

# 创建持久化客户端
client = chromadb.PersistentClient(path="./data/chroma")

# 获取或创建 collection（不使用默认 embedding）
collection = client.get_or_create_collection(
    name="memories",
    metadata={"description": "Long-term memories for chat"}
)
```

### 自定义 Embedding 函数

```python
from openai import OpenAI

class EmbeddingService:
    def __init__(self, base_url: str, api_key: str, model: str):
        self.client = OpenAI(base_url=base_url, api_key=api_key)
        self.model = model

    def embed(self, texts: list[str]) -> list[list[float]]:
        response = self.client.embeddings.create(
            model=self.model,
            input=texts
        )
        return [item.embedding for item in response.data]
```

### 存储记忆

```python
def store_memory(
    memory_id: str,
    content: str,
    source: str,
    embedding_service: EmbeddingService
):
    # 生成向量
    embeddings = embedding_service.embed([content])

    # 存入 ChromaDB
    collection.add(
        ids=[memory_id],
        documents=[content],
        embeddings=embeddings,
        metadatas=[{"source": source}]
    )
```

### 检索相关记忆

```python
def retrieve_memories(
    query: str,
    embedding_service: EmbeddingService,
    top_k: int = 5
) -> list[dict]:
    # 向量化查询
    query_embedding = embedding_service.embed([query])[0]

    # 搜索
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )

    # 返回结果
    memories = []
    for i, (doc, metadata, id) in enumerate(zip(
        results["documents"][0],
        results["metadatas"][0],
        results["ids"][0]
    )):
        memories.append({
            "id": id,
            "content": doc,
            "source": metadata["source"]
        })

    return memories
```

### 记录记忆使用

```python
def record_memory_usage(
    memory_ids: list[str],
    topic_id: str,
    message_id: str
):
    for memory_id in memory_ids:
        # 插入使用记录
        db.execute("""
            INSERT INTO memory_usage (id, memory_id, topic_id, message_id)
            VALUES (?, ?, ?, ?)
        """, (uuid4(), memory_id, topic_id, message_id))

        # 更新统计
        db.execute("""
            UPDATE memories
            SET use_count = use_count + 1,
                last_used_at = CURRENT_TIMESTAMP
            WHERE id = ?
        """, (memory_id,))
```

### 更新记忆（重新向量化）

```python
def update_memory(
    memory_id: str,
    new_content: str,
    embedding_service: EmbeddingService
):
    # 生成新向量
    embeddings = embedding_service.embed([new_content])

    # 更新 ChromaDB
    collection.update(
        ids=[memory_id],
        documents=[new_content],
        embeddings=embeddings
    )

    # 更新 SQLite
    db.execute("""
        UPDATE memories SET content = ? WHERE id = ?
    """, (new_content, memory_id))
```

### 删除记忆

```python
def delete_memory(memory_id: str):
    # 从 ChromaDB 删除
    collection.delete(ids=[memory_id])

    # 从 SQLite 删除（memory_usage 会级联删除）
    db.execute("DELETE FROM memories WHERE id = ?", (memory_id,))
```

## 记忆使用统计

### 查询记忆列表（带统计）

```python
def get_memories_with_stats(page: int = 1, page_size: int = 20):
    offset = (page - 1) * page_size
    return db.execute("""
        SELECT
            id, content, source, source_topic_id, source_message_id,
            use_count, created_at, last_used_at
        FROM memories
        ORDER BY use_count DESC, last_used_at DESC
        LIMIT ? OFFSET ?
    """, (page_size, offset))
```

### 查询记忆使用详情

```python
def get_memory_usage_details(memory_id: str):
    return db.execute("""
        SELECT
            mu.used_at,
            t.id as topic_id,
            t.title as topic_title,
            mu.message_id
        FROM memory_usage mu
        JOIN topics t ON mu.topic_id = t.id
        WHERE mu.memory_id = ?
        ORDER BY mu.used_at DESC
    """, (memory_id,))
```

## 注意事项

1. **Embedding 一致性**：同一个项目应使用相同的 embedding 模型，否则向量不可比较。更换模型需要重新向量化所有记忆。

2. **性能考虑**：
   - 随着记忆增多，检索速度可能变慢
   - ChromaDB 默认使用 HNSW 索引，对大规模数据友好
   - 可以考虑定期清理低使用率的记忆

3. **记忆质量**：
   - 不是所有对话都值得记忆
   - 后续可以添加记忆筛选逻辑（如过滤太短的消息）

4. **隐私考虑**：
   - 所有对话都会被记忆
   - 单用户版本问题不大
   - 删除话题时相关记忆的 source 会被置空但记忆保留
